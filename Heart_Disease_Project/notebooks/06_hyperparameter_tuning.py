# -*- coding: utf-8 -*-
"""06_hyperparameter_tuning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dzIdoNfMt3m2ht-xSsB82_59HAXGNl_E

<h2> Les Imports </h2>
"""

import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

"""<h2> Chargement de données </h2>
les données nettoyées et selectionées: heart_selected_features.csv
"""

df = pd.read_csv("heart_selected_features.csv")
df.head()

"""<h2> Séparation X/y & Train / Test"""

X = df.drop("target", axis=1)
y = df["target"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

"""<h2> Les fonction a Utiliser pour Evaluation </h2>"""

def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    return {
        "Accuracy": accuracy_score(y_test, y_pred),
        "Precision": precision_score(y_test, y_pred),
        "Recall": recall_score(y_test, y_pred),
        "F1 Score": f1_score(y_test, y_pred)
    }

"""<h2> Modele: Régression Logistique </h2>"""

log_reg = LogisticRegression(max_iter=2000)
param_grid_lr = {
    "C": [0.1, 1, 5, 10],
    "solver": ["liblinear", "lbfgs"]
}
grid_lr = GridSearchCV(
    log_reg,
    param_grid_lr,
    cv=5,
    scoring="accuracy",
    n_jobs=-1
)
grid_lr.fit(X_train, y_train)
best_lr = grid_lr.best_estimator_
print("Meilleurs paramètres (Logistic Regression) :", grid_lr.best_params_)

print("--"*15, "Evaluation", "--"*15)
lr_results = evaluate_model(best_lr, X_test, y_test)
lr_results

"""<h2> Modele: Random Forest"""

rf = RandomForestClassifier()
param_dist_rf = {
    "n_estimators": [50, 100, 150, 200, 300],
    "max_depth": [None, 5, 10, 20],
    "min_samples_split": [2, 5, 10],
    "min_samples_leaf": [1, 2, 4]
}
rand_rf = RandomizedSearchCV(
    rf,
    param_dist_rf,
    cv=5,
    scoring="accuracy",
    n_iter=20,
    random_state=42,
    n_jobs=-1
)
rand_rf.fit(X_train, y_train)
best_rf = rand_rf.best_estimator_

print("Meilleurs paramètres (Random Forest) :", rand_rf.best_params_)

print("--"*15, "Evaluation", "--"*15)
rf_results = evaluate_model(best_rf, X_test, y_test)
rf_results

"""<h2> Modele: SVM </h2>"""

svm_model = SVC()
param_grid_svm = {
    "C": [0.1, 1, 5, 10],
    "kernel": ["linear", "rbf"],
    "gamma": ["scale", "auto"]
}
grid_svm = GridSearchCV(
    svm_model,
    param_grid_svm,
    cv=5,
    scoring="accuracy",
    n_jobs=-1
)
grid_svm.fit(X_train, y_train)
best_svm = grid_svm.best_estimator_
print("Meilleurs paramètres (SVM) :", grid_svm.best_params_)

print("--"*15, "Evaluation", "--"*15)
svm_results = evaluate_model(best_svm, X_test, y_test)
svm_results

"""<h2> Comparaison Finale </h2>"""

results = pd.DataFrame({
    "LogReg": lr_results,
    "RandomForest": rf_results,
    "SVM": svm_results
})
results

"""<h2> Export du Meilleur Modele </h2>"""

import joblib

best_model_name = results.loc["F1 Score"].idxmax()
if best_model_name == "LogReg":
    best_model = best_lr
elif best_model_name == "RandomForest":
    best_model = best_rf
else:
    best_model = best_svm

joblib.dump(best_model, "final_model.pkl")

print("Modèle exporté sous : best_model.pkl")
print("Meilleur modèle :", best_model_name)